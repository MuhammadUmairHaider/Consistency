{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils import data\n",
    "import torch.optim as optim\n",
    "from utilities import train, eval, pad, compute_masks, mask\n",
    "from POS_dataset import PosDataset\n",
    "\n",
    "import nltk\n",
    "tagged_sents = nltk.corpus.treebank.tagged_sents()\n",
    "\n",
    "tags = list(set(word_pos[1] for sent in tagged_sents for word_pos in sent))\n",
    "\n",
    "\",\".join(tags)\n",
    "\n",
    "tags = [\"<pad>\"] + tags\n",
    "\n",
    "tag2idx = {tag:idx for idx, tag in enumerate(tags)}\n",
    "idx2tag = {idx:tag for idx, tag in enumerate(tags)}\n",
    "\n",
    "# Let's split the data into train and test (or eval)\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_data, test_data = train_test_split(tagged_sents, test_size=.1)\n",
    "len(train_data), len(test_data)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, TokenClassificationPipeline\n",
    "import torch\n",
    "\n",
    "model_name = \"QCRI/bert-base-multilingual-cased-pos-english\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, vocab_size=None):\n",
    "        super().__init__()\n",
    "        self.model = AutoModelForTokenClassification.from_pretrained(model_name)\n",
    "        self.bert = self.model.bert\n",
    "        self.masking_layer = torch.ones(768).to(\"cuda\")\n",
    "\n",
    "        self.fc = nn.Linear(768, vocab_size)\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        '''\n",
    "        x: (N, T). int64\n",
    "        y: (N, T). int64\n",
    "        '''\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        if self.training:\n",
    "            self.bert.train()\n",
    "            encoded_layers = self.bert(x)\n",
    "            enc = encoded_layers[-1]\n",
    "        else:\n",
    "            self.bert.eval()\n",
    "            with torch.no_grad():\n",
    "                encoded_layers = self.bert(x)\n",
    "                enc = encoded_layers[-1]\n",
    "        # enc = nn.ReLU(enc)\n",
    "        enc = enc * self.masking_layer\n",
    "        logits = self.fc(enc)\n",
    "        y_hat = logits.argmax(-1)\n",
    "        confidence = logits.softmax(-1).max(-1).values\n",
    "        return enc, logits, y, y_hat, confidence\n",
    "    \n",
    "    \n",
    "model = Net(vocab_size=len(tag2idx))\n",
    "model.to(device)\n",
    "\n",
    "train_dataset = PosDataset(train_data, tokenizer, tag2idx)\n",
    "eval_dataset = PosDataset(test_data, tokenizer, tag2idx)\n",
    "\n",
    "train_iter = data.DataLoader(dataset=train_dataset,\n",
    "                             batch_size=8,\n",
    "                             shuffle=True,\n",
    "                             num_workers=1,\n",
    "                             collate_fn=pad)\n",
    "test_iter = data.DataLoader(dataset=eval_dataset,\n",
    "                             batch_size=1,\n",
    "                             shuffle=False,\n",
    "                             num_workers=1,\n",
    "                             collate_fn=pad)\n",
    "activation_iter = data.DataLoader(dataset=train_dataset+eval_dataset,\n",
    "                             batch_size=1,\n",
    "                             shuffle=False,\n",
    "                             num_workers=1,\n",
    "                             collate_fn=pad)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.0001)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "\n",
    "for i in range(10):\n",
    "    train(model, train_iter, optimizer, criterion)\n",
    "\n",
    "from utilities import compute_masks, mask, eval\n",
    "\n",
    "model.masking_layer = torch.ones(768).to(\"cuda\")\n",
    "activation_iter = data.DataLoader(dataset=train_dataset+eval_dataset,\n",
    "                             batch_size=1,\n",
    "                             shuffle=False,\n",
    "                             num_workers=1,\n",
    "                             collate_fn=pad)\n",
    "\n",
    "enc_dict = eval(model, activation_iter, idx2tag, tag2idx,33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_dict = eval(model, activation_iter, idx2tag, tag2idx,33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def compute_masks(fc_vals, percent):\n",
    "    # Convert input to numpy array\n",
    "    fc_vals_array = np.array(fc_vals)\n",
    "    \n",
    "    # Compute statistics\n",
    "    mean_vals = np.mean(np.abs(fc_vals_array), axis=0)\n",
    "    std_vals = np.std(fc_vals_array, axis=0)\n",
    "    min_vals = np.min(fc_vals_array, axis=0)\n",
    "    max_vals = np.max(fc_vals_array, axis=0)\n",
    "    \n",
    "    # Normalize standard deviation\n",
    "    std_vals_normalized = (std_vals - min_vals) / (max_vals - min_vals)\n",
    "    \n",
    "    # Convert to PyTorch tensors\n",
    "    mean_vals_tensor = torch.from_numpy(mean_vals)\n",
    "    std_vals_tensor = torch.from_numpy(std_vals_normalized)\n",
    "    \n",
    "    # Compute masks\n",
    "    mask_max = compute_max_mask(mean_vals_tensor, percent)\n",
    "    mask_std = compute_std_mask(std_vals_tensor, percent)\n",
    "    mask_max_low_std = compute_max_low_std_mask(mean_vals_tensor, std_vals_tensor, percent)\n",
    "    mask_intersection = torch.logical_or(mask_std, mask_max).float()\n",
    "    \n",
    "    return mask_max, mask_std, mask_intersection, mask_max_low_std\n",
    "\n",
    "def compute_max_mask(values, percent):\n",
    "    sorted_indices = torch.argsort(values, descending=True)\n",
    "    mask_count = int(percent * len(values))\n",
    "    mask = torch.ones_like(values)\n",
    "    mask[sorted_indices[:mask_count]] = 0.0\n",
    "    return mask\n",
    "\n",
    "def compute_std_mask(values, percent):\n",
    "    sorted_indices = torch.argsort(values, descending=False)\n",
    "    mask_count = int(percent * len(values))\n",
    "    mask = torch.ones_like(values)\n",
    "    mask[sorted_indices[:mask_count]] = 0.0\n",
    "    return mask\n",
    "\n",
    "def compute_max_low_std_mask(mean_vals, std_vals, percent):\n",
    "    # Get indices of bottom 50% std values\n",
    "    bottom_50_percent_std_count = int(0.99 * len(std_vals))\n",
    "    bottom_50_percent_std_indices = torch.argsort(std_vals)[:bottom_50_percent_std_count]\n",
    "    \n",
    "    # Create a mask for bottom 50% std values\n",
    "    bottom_50_percent_std_mask = torch.zeros_like(std_vals, dtype=torch.bool)\n",
    "    bottom_50_percent_std_mask[bottom_50_percent_std_indices] = True\n",
    "    \n",
    "    # Filter mean values\n",
    "    mean_vals_filtered = mean_vals.clone()\n",
    "    mean_vals_filtered[~bottom_50_percent_std_mask] = float('-inf')\n",
    "    \n",
    "    # Compute mask\n",
    "    return compute_max_mask(mean_vals_filtered, percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, fc in enumerate(enc_dict):\n",
    "    print(f\"Layer {fc}\", i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import numpy as np\n",
    "from ipywidgets import VBox, Output\n",
    "from IPython.display import display\n",
    "\n",
    "output_widgets = []\n",
    "\n",
    "for i, fc1 in enumerate(enc_dict):\n",
    "    tag = idx2tag[fc1]\n",
    "    fc1 = enc_dict[fc1]\n",
    "    \n",
    "    fc1 = np.array(fc1)\n",
    "    mask_max, mask_std, mask_intersection, mask_max_low_std = compute_masks(fc1, 0.15)\n",
    "    \n",
    "    m = np.mean(np.abs(fc1), axis=0)\n",
    "    s = np.std(fc1, axis=0)\n",
    "    min_val = np.min(fc1, axis=0)\n",
    "    max_val = np.max(fc1, axis=0)\n",
    "    \n",
    "    # Normalize std and mean\n",
    "    s_norm = (s - min_val) / (max_val - min_val)\n",
    "    m_norm = m#(m - min_val) / (max_val - min_val)\n",
    "    \n",
    "    # Create indices for different masks\n",
    "    indices_max = np.where(mask_max == 0)[0]\n",
    "    indices_std = np.where(mask_std == 0)[0]\n",
    "    indices_intersection = np.intersect1d(indices_max, indices_std)\n",
    "    indices_max_minus_std = np.setdiff1d(indices_max, indices_std)\n",
    "    indices_std_minus_max = np.setdiff1d(indices_std, indices_max)\n",
    "    \n",
    "    # Count the indices in each set\n",
    "    count_all = len(m_norm)\n",
    "    count_max = len(indices_max)\n",
    "    count_std = len(indices_std)\n",
    "    count_intersection = len(indices_intersection)\n",
    "    count_max_minus_std = len(indices_max_minus_std)\n",
    "    count_std_minus_max = len(indices_std_minus_max)\n",
    "    \n",
    "    out = Output()\n",
    "    with out:\n",
    "        # Create subplots with counts in titles\n",
    "        fig = make_subplots(rows=2, cols=3, \n",
    "                            subplot_titles=(f\"All Activations (Count: {count_all})\",\n",
    "                                            f\"Max Mask (Count: {count_max})\", \n",
    "                                            f\"Std Mask (Count: {count_std})\", \n",
    "                                            f\"Intersection (Count: {count_intersection})\",\n",
    "                                            f\"Max - Std (Count: {count_max_minus_std})\", \n",
    "                                            f\"Std - Max (Count: {count_std_minus_max})\"))\n",
    "        \n",
    "        # Helper function to add traces\n",
    "        def add_traces(indices, row, col):\n",
    "            indices_list = list(indices)  # Convert range or numpy array to list\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=indices_list,\n",
    "                    y=m_norm[indices_list],\n",
    "                    mode='markers',\n",
    "                    name='Mean',\n",
    "                    marker=dict(size=3, color='blue'),\n",
    "                    showlegend=(row == 1 and col == 1)\n",
    "                ),\n",
    "                row=row, col=col\n",
    "            )\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=indices_list,\n",
    "                    y=s_norm[indices_list],\n",
    "                    mode='markers',\n",
    "                    name='Std Dev',\n",
    "                    marker=dict(size=3, color='red'),\n",
    "                    showlegend=(row == 1 and col == 1)\n",
    "                ),\n",
    "                row=row, col=col\n",
    "            )\n",
    "            for j in indices_list:\n",
    "                fig.add_trace(\n",
    "                    go.Scatter(\n",
    "                        x=[j, j],\n",
    "                        y=[m_norm[j], s_norm[j]],\n",
    "                        mode='lines',\n",
    "                        line=dict(color='gray', width=0.5),\n",
    "                        showlegend=False\n",
    "                    ),\n",
    "                    row=row, col=col\n",
    "                )\n",
    "        \n",
    "        # Add traces for all activations\n",
    "        add_traces(range(len(m_norm)), 1, 1)\n",
    "        \n",
    "        # Add traces for other plots\n",
    "        add_traces(indices_max, 1, 2)\n",
    "        add_traces(indices_std, 1, 3)\n",
    "        add_traces(indices_intersection, 2, 1)\n",
    "        add_traces(indices_max_minus_std, 2, 2)\n",
    "        add_traces(indices_std_minus_max, 2, 3)\n",
    "        \n",
    "        # Update layout\n",
    "        fig.update_layout(\n",
    "            title=f'Mean and Standard Deviation of Activations - Class {i+1}'+ tag,\n",
    "            height=1200,\n",
    "            width=1800,\n",
    "            hovermode='closest'\n",
    "        )\n",
    "        \n",
    "        # Update x and y axis labels for all subplots\n",
    "        for row in range(1, 3):\n",
    "            for col in range(1, 4):\n",
    "                fig.update_xaxes(title_text=\"Activation Index\", row=row, col=col)\n",
    "                fig.update_yaxes(title_text=\"Normalized Value\", row=row, col=col)\n",
    "        \n",
    "        display(fig)\n",
    "    \n",
    "    output_widgets.append(out)\n",
    "\n",
    "# Display all figures in a vertical box\n",
    "# display(VBox(output_widgets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "from ipywidgets import VBox, Output\n",
    "from utilities import compute_masks\n",
    "from IPython.display import display\n",
    "\n",
    "def create_index_tracking_plot(indices_per_class, title):\n",
    "    num_classes = len(indices_per_class)\n",
    "    all_indices = sorted(set.union(*[set(indices) for indices in indices_per_class]))\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    \n",
    "    # Create a color scale\n",
    "    color_scale = px.colors.diverging.RdYlGn_r  # Red to Yellow to Green color scale\n",
    "\n",
    "    # Add edges for indices present in multiple classes\n",
    "    for idx in all_indices:\n",
    "        classes_with_idx = [i for i, indices in enumerate(indices_per_class) if idx in indices]\n",
    "        if len(classes_with_idx) > 1:\n",
    "            x = [idx] * len(classes_with_idx)\n",
    "            y = classes_with_idx\n",
    "            color_index = (len(classes_with_idx) - 1) / (num_classes - 1)  # Normalize to [0, 1]\n",
    "            edge_color = px.colors.sample_colorscale(color_scale, [color_index])[0]\n",
    "            \n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=x,\n",
    "                y=y,\n",
    "                mode='lines',\n",
    "                line=dict(color=edge_color, width=2),\n",
    "                hoverinfo='text',\n",
    "                hovertext=f'Index: {idx}<br>Present in {len(classes_with_idx)} classes',\n",
    "                showlegend=False\n",
    "            ))\n",
    "    \n",
    "    # Add scatter plots for each class\n",
    "    for class_idx, indices in enumerate(indices_per_class):\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=indices,\n",
    "            y=[class_idx] * len(indices),\n",
    "            mode='markers',\n",
    "            name=f'Class {class_idx + 1}',\n",
    "            marker=dict(size=4, symbol='circle', color='black'),\n",
    "            hoverinfo='text',\n",
    "            hovertext=[f'Index: {idx}<br>Class: {class_idx + 1}' for idx in indices]\n",
    "        ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        xaxis_title='Activation Index',\n",
    "        yaxis_title='Class',\n",
    "        yaxis=dict(\n",
    "            tickmode='array',\n",
    "            tickvals=list(range(num_classes)),\n",
    "            ticktext=[f'Class {i+1}' for i in range(num_classes)]\n",
    "        ),\n",
    "        hovermode='closest',\n",
    "        width=1500,\n",
    "        height=800,\n",
    "        plot_bgcolor='white',\n",
    "        showlegend=False\n",
    "    )\n",
    "    \n",
    "    fig.update_xaxes(showgrid=True, gridwidth=1, gridcolor='LightGrey')\n",
    "    fig.update_yaxes(showgrid=True, gridwidth=1, gridcolor='LightGrey')\n",
    "    \n",
    "    # Add color bar\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=[None],\n",
    "        y=[None],\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            colorscale=color_scale,\n",
    "            showscale=True,\n",
    "            cmin=1,\n",
    "            cmax=num_classes,\n",
    "            colorbar=dict(\n",
    "                title='Number of Classes',\n",
    "                tickvals=list(range(1, num_classes+1)),\n",
    "                ticktext=list(range(1, num_classes+1))\n",
    "            )\n",
    "        ),\n",
    "        hoverinfo='none',\n",
    "        showlegend=False\n",
    "    ))\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Collect indices for each class\n",
    "max_indices_per_class = []\n",
    "std_indices_per_class = []\n",
    "\n",
    "for fc1 in all_fc_vals:\n",
    "    mask_max, mask_std = compute_masks(fc1, 0.15)\n",
    "    max_indices_per_class.append(np.where(mask_max == 0)[0])\n",
    "    std_indices_per_class.append(np.where(mask_std == 0)[0])\n",
    "\n",
    "# Create and display visualizations\n",
    "output_widgets = []\n",
    "\n",
    "out = Output()\n",
    "with out:\n",
    "    fig_max = create_index_tracking_plot(max_indices_per_class, 'Max Mask Indices Across Classes')\n",
    "    display(fig_max)\n",
    "output_widgets.append(out)\n",
    "\n",
    "out = Output()\n",
    "with out:\n",
    "    fig_std = create_index_tracking_plot(std_indices_per_class, 'Std Mask Indices Across Classes')\n",
    "    display(fig_std)\n",
    "output_widgets.append(out)\n",
    "\n",
    "# Display all visualizations\n",
    "# display(VBox(output_widgets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "memit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
