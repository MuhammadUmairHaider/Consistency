{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording activations...\n",
      "Processed 29780 samples for class 0\n",
      "Recording activations...\n",
      "Processed 37569 samples for class 1\n",
      "Recording activations...\n",
      "Processed 67349 samples for class 2\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from utilities import get_model_distilbert\n",
    "\n",
    "mask_layer = 5\n",
    "text_tag = \"sentence\"\n",
    "compliment = True\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "# Check if a GPU is available and use it\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load the dataset\n",
    "dataset_all = load_dataset(\"stanfordnlp/sst2\")\n",
    "# Select the train split\n",
    "dataset_all = dataset_all['train']\n",
    "model = get_model_distilbert(\"distilbert-base-uncased-finetuned-sst-2-english\", mask_layer)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "batch_size = 32  # You can adjust this based on your GPU memory\n",
    "all_fc_vals = []\n",
    "\n",
    "for j in range(0,3):\n",
    "    dataset = dataset_all.filter(lambda x: x['label'] in [j])\n",
    "    dataset_complement = dataset_all.filter(lambda x: x['label'] not in [j])\n",
    "    \n",
    "    if(j==2):\n",
    "        dataset = dataset_all\n",
    "    \n",
    "    print(\"Recording activations...\")\n",
    "    fc_vals = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(dataset), batch_size):\n",
    "            batch = dataset[i:i+batch_size]\n",
    "            texts = batch['sentence']\n",
    "            inputs = tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "            outputs = model(**inputs)\n",
    "            fc_vals.extend(outputs[1][mask_layer+1][:, 0].cpu().numpy())\n",
    "    \n",
    "    all_fc_vals.append(fc_vals)\n",
    "    print(f\"Processed {len(fc_vals)} samples for class {j}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from ipywidgets import VBox, Output\n",
    "\n",
    "output_widgets = []\n",
    "\n",
    "for i, v in enumerate(all_fc_vals):\n",
    "    v = np.array(v)\n",
    "    m = np.mean(np.abs(v), axis=0)\n",
    "    s = np.std(v, axis=0)\n",
    "    \n",
    "    \n",
    "    min_val = np.min(v, axis=0)\n",
    "    max_val = np.max(v, axis=0)    \n",
    "    \n",
    "    s = (s-min_val) / (max_val - min_val)\n",
    "    # m = (m-min_val) / (max_val - min_val)\n",
    "\n",
    "    # Create a new figure for each set of values\n",
    "    out = Output()\n",
    "    with out:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "\n",
    "        # Plot the mean\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(m, 'bo', markersize=4)\n",
    "        plt.title(f'Mean of Activations - Set {i+1}')\n",
    "        plt.xlabel('Activation Index')\n",
    "        plt.ylabel('Mean Value')\n",
    "        plt.ylim(0, np.max(m))  # Ensure y-axis starts at 0\n",
    "\n",
    "        # Plot the standard deviation\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(s, 'ro', markersize=4)\n",
    "        plt.title(f'Standard Deviation of Activations - Set {i+1}')\n",
    "        plt.xlabel('Activation Index')\n",
    "        plt.ylabel('Standard Deviation')\n",
    "        plt.ylim(0, np.max(s))  # Ensure y-axis starts at 0\n",
    "\n",
    "        # Show the plots\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    output_widgets.append(out)\n",
    "\n",
    "# Display all figures in a vertical box\n",
    "VBox(output_widgets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import numpy as np\n",
    "from ipywidgets import VBox, Output\n",
    "\n",
    "output_widgets = []\n",
    "\n",
    "for i, v in enumerate(all_fc_vals):\n",
    "    v = np.array(v)\n",
    "    m = np.mean(np.abs(v), axis=0)\n",
    "    s = np.std(v, axis=0)\n",
    "    \n",
    "    min_val = np.min(v, axis=0)\n",
    "    max_val = np.max(v, axis=0)\n",
    "    s = (s-min_val) / (max_val - min_val)\n",
    "    # m = (m-min_val) / (max_val - min_val)\n",
    "    # Create a new figure for each set of values\n",
    "    out = Output()\n",
    "    with out:\n",
    "        fig = go.Figure()\n",
    "\n",
    "        # Plot the mean with markers\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=list(range(768)),\n",
    "            y=m,\n",
    "            mode='markers',\n",
    "            name='Mean',\n",
    "            marker=dict(size=3, color='blue')\n",
    "        ))\n",
    "\n",
    "        # Plot the standard deviation with markers\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=list(range(768)),\n",
    "            y=s,\n",
    "            mode='markers',\n",
    "            name='Std Dev',\n",
    "            marker=dict(size=3, color='red')\n",
    "        ))\n",
    "\n",
    "        # Add lines connecting corresponding points\n",
    "        for j in range(768):\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=[j, j],\n",
    "                y=[m[j], s[j]],\n",
    "                mode='lines',\n",
    "                line=dict(color='gray', width=0.5),\n",
    "                showlegend=False\n",
    "            ))\n",
    "\n",
    "        # Update layout\n",
    "        fig.update_layout(\n",
    "            title=f'Mean and Standard Deviation of Activations - Set {i+1}',\n",
    "            xaxis_title='Activation Index',\n",
    "            yaxis_title='Value',\n",
    "            yaxis=dict(range=[0, max(np.max(m), np.max(s)) * 1.1]),\n",
    "            height=600,\n",
    "            width=1000,\n",
    "            hovermode='closest'\n",
    "        )\n",
    "\n",
    "        fig.show()\n",
    "    \n",
    "    output_widgets.append(out)\n",
    "\n",
    "# Display all figures in a vertical box\n",
    "# VBox(output_widgets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import numpy as np\n",
    "from ipywidgets import VBox, Output\n",
    "import importlib\n",
    "import utilities\n",
    "\n",
    "importlib.reload(utilities)\n",
    "from utilities import compute_masks\n",
    "from IPython.display import display\n",
    "\n",
    "output_widgets = []\n",
    "\n",
    "for i, fc1 in enumerate(all_fc_vals):\n",
    "    fc1 = np.array(fc1)\n",
    "    mask_max, mask_std, mask_intersection, mask_max_low_std, mask_std_high_max = compute_masks(fc1, 0.15)\n",
    "    mask_std = mask_std_high_max\n",
    "    \n",
    "    m = np.mean(np.abs(fc1), axis=0)\n",
    "    s = np.std(fc1, axis=0)\n",
    "    min_val = np.min(fc1, axis=0)\n",
    "    max_val = np.max(fc1, axis=0)\n",
    "    \n",
    "    # Normalize std and mean\n",
    "    s_norm = (s - min_val) / (max_val - min_val)\n",
    "    m_norm = m#(m - min_val) / (max_val - min_val)\n",
    "    \n",
    "    # Create indices for different masks\n",
    "    indices_max = np.where(mask_max == 0)[0]\n",
    "    indices_std = np.where(mask_std == 0)[0]\n",
    "    indices_intersection = np.intersect1d(indices_max, indices_std)\n",
    "    indices_max_minus_std = np.setdiff1d(indices_max, indices_std)\n",
    "    indices_std_minus_max = np.setdiff1d(indices_std, indices_max)\n",
    "    \n",
    "    # Count the indices in each set\n",
    "    count_max = len(indices_max)\n",
    "    count_std = len(indices_std)\n",
    "    count_intersection = len(indices_intersection)\n",
    "    count_max_minus_std = len(indices_max_minus_std)\n",
    "    count_std_minus_max = len(indices_std_minus_max)\n",
    "    \n",
    "    out = Output()\n",
    "    with out:\n",
    "        # Create subplots with counts in titles\n",
    "        fig = make_subplots(rows=2, cols=3, \n",
    "                            subplot_titles=(f\"Max Mask (Count: {count_max})\", \n",
    "                                            f\"Std Mask (Count: {count_std})\", \n",
    "                                            f\"Intersection (Count: {count_intersection})\",\n",
    "                                            f\"Max - Std (Count: {count_max_minus_std})\", \n",
    "                                            f\"Std - Max (Count: {count_std_minus_max})\"))\n",
    "        \n",
    "        # Helper function to add traces\n",
    "        def add_traces(indices, row, col):\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=indices,\n",
    "                    y=m_norm[indices],\n",
    "                    mode='markers',\n",
    "                    name='Mean',\n",
    "                    marker=dict(size=3, color='blue'),\n",
    "                    showlegend=(row == 1 and col == 1)\n",
    "                ),\n",
    "                row=row, col=col\n",
    "            )\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=indices,\n",
    "                    y=s_norm[indices],\n",
    "                    mode='markers',\n",
    "                    name='Std Dev',\n",
    "                    marker=dict(size=3, color='red'),\n",
    "                    showlegend=(row == 1 and col == 1)\n",
    "                ),\n",
    "                row=row, col=col\n",
    "            )\n",
    "            for j in indices:\n",
    "                fig.add_trace(\n",
    "                    go.Scatter(\n",
    "                        x=[j, j],\n",
    "                        y=[m_norm[j], s_norm[j]],\n",
    "                        mode='lines',\n",
    "                        line=dict(color='gray', width=0.5),\n",
    "                        showlegend=False\n",
    "                    ),\n",
    "                    row=row, col=col\n",
    "                )\n",
    "        \n",
    "        # Add traces for all plots\n",
    "        add_traces(indices_max, 1, 1)\n",
    "        add_traces(indices_std, 1, 2)\n",
    "        add_traces(indices_intersection, 1, 3)\n",
    "        add_traces(indices_max_minus_std, 2, 1)\n",
    "        add_traces(indices_std_minus_max, 2, 2)\n",
    "        \n",
    "        # Update layout\n",
    "        fig.update_layout(\n",
    "            title=f'Mean and Standard Deviation of Activations - Class {i+1}',\n",
    "            height=1200,\n",
    "            width=1800,\n",
    "            hovermode='closest'\n",
    "        )\n",
    "        \n",
    "        # Update x and y axis labels for all subplots\n",
    "        for row in range(1, 3):\n",
    "            for col in range(1, 4):\n",
    "                if row == 2 and col == 3:\n",
    "                    continue  # Skip the empty subplot\n",
    "                fig.update_xaxes(title_text=\"Activation Index\", row=row, col=col)\n",
    "                fig.update_yaxes(title_text=\"Normalized Value\", row=row, col=col)\n",
    "        \n",
    "        display(fig)\n",
    "    \n",
    "    output_widgets.append(out)\n",
    "\n",
    "# Display all figures in a vertical box\n",
    "# display(VBox(output_widgets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import numpy as np\n",
    "from ipywidgets import VBox, Output\n",
    "from utilities import compute_masks\n",
    "from IPython.display import display\n",
    "\n",
    "output_widgets = []\n",
    "\n",
    "for i, fc1 in enumerate(all_fc_vals):\n",
    "    fc1 = np.array(fc1)\n",
    "    mask_max, mask_std = compute_masks(fc1, 0.15)\n",
    "    \n",
    "    m = np.mean(np.abs(fc1), axis=0)\n",
    "    s = np.std(fc1, axis=0)\n",
    "    min_val = np.min(fc1, axis=0)\n",
    "    max_val = np.max(fc1, axis=0)\n",
    "    \n",
    "    # Normalize std and mean\n",
    "    s_norm = (s - min_val) / (max_val - min_val)\n",
    "    m_norm = m#(m - min_val) / (max_val - min_val)\n",
    "    \n",
    "    # Create indices for different masks\n",
    "    indices_max = np.where(mask_max == 0)[0]\n",
    "    indices_std = np.where(mask_std == 0)[0]\n",
    "    indices_intersection = np.intersect1d(indices_max, indices_std)\n",
    "    indices_max_minus_std = np.setdiff1d(indices_max, indices_std)\n",
    "    indices_std_minus_max = np.setdiff1d(indices_std, indices_max)\n",
    "    \n",
    "    # Count the indices in each set\n",
    "    count_all = len(m_norm)\n",
    "    count_max = len(indices_max)\n",
    "    count_std = len(indices_std)\n",
    "    count_intersection = len(indices_intersection)\n",
    "    count_max_minus_std = len(indices_max_minus_std)\n",
    "    count_std_minus_max = len(indices_std_minus_max)\n",
    "    \n",
    "    out = Output()\n",
    "    with out:\n",
    "        # Create subplots with counts in titles\n",
    "        fig = make_subplots(rows=2, cols=3, \n",
    "                            subplot_titles=(f\"All Activations (Count: {count_all})\",\n",
    "                                            f\"Max Mask (Count: {count_max})\", \n",
    "                                            f\"Std Mask (Count: {count_std})\", \n",
    "                                            f\"Intersection (Count: {count_intersection})\",\n",
    "                                            f\"Max - Std (Count: {count_max_minus_std})\", \n",
    "                                            f\"Std - Max (Count: {count_std_minus_max})\"))\n",
    "        \n",
    "        # Helper function to add traces\n",
    "        def add_traces(indices, row, col):\n",
    "            indices_list = list(indices)  # Convert range or numpy array to list\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=indices_list,\n",
    "                    y=m_norm[indices_list],\n",
    "                    mode='markers',\n",
    "                    name='Mean',\n",
    "                    marker=dict(size=3, color='blue'),\n",
    "                    showlegend=(row == 1 and col == 1)\n",
    "                ),\n",
    "                row=row, col=col\n",
    "            )\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=indices_list,\n",
    "                    y=s_norm[indices_list],\n",
    "                    mode='markers',\n",
    "                    name='Std Dev',\n",
    "                    marker=dict(size=3, color='red'),\n",
    "                    showlegend=(row == 1 and col == 1)\n",
    "                ),\n",
    "                row=row, col=col\n",
    "            )\n",
    "            for j in indices_list:\n",
    "                fig.add_trace(\n",
    "                    go.Scatter(\n",
    "                        x=[j, j],\n",
    "                        y=[m_norm[j], s_norm[j]],\n",
    "                        mode='lines',\n",
    "                        line=dict(color='gray', width=0.5),\n",
    "                        showlegend=False\n",
    "                    ),\n",
    "                    row=row, col=col\n",
    "                )\n",
    "        \n",
    "        # Add traces for all activations\n",
    "        add_traces(range(len(m_norm)), 1, 1)\n",
    "        \n",
    "        # Add traces for other plots\n",
    "        add_traces(indices_max, 1, 2)\n",
    "        add_traces(indices_std, 1, 3)\n",
    "        add_traces(indices_intersection, 2, 1)\n",
    "        add_traces(indices_max_minus_std, 2, 2)\n",
    "        add_traces(indices_std_minus_max, 2, 3)\n",
    "        \n",
    "        # Update layout\n",
    "        fig.update_layout(\n",
    "            title=f'Mean and Standard Deviation of Activations - Class {i+1}',\n",
    "            height=1200,\n",
    "            width=1800,\n",
    "            hovermode='closest'\n",
    "        )\n",
    "        \n",
    "        # Update x and y axis labels for all subplots\n",
    "        for row in range(1, 3):\n",
    "            for col in range(1, 4):\n",
    "                fig.update_xaxes(title_text=\"Activation Index\", row=row, col=col)\n",
    "                fig.update_yaxes(title_text=\"Normalized Value\", row=row, col=col)\n",
    "        \n",
    "        display(fig)\n",
    "    \n",
    "    output_widgets.append(out)\n",
    "\n",
    "# Display all figures in a vertical box\n",
    "# display(VBox(output_widgets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "from ipywidgets import VBox, Output\n",
    "from utilities import compute_masks\n",
    "from IPython.display import display\n",
    "\n",
    "def create_index_tracking_plot(indices_per_class, title):\n",
    "    num_classes = len(indices_per_class)\n",
    "    all_indices = sorted(set.union(*[set(indices) for indices in indices_per_class]))\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    \n",
    "    # Create a color scale\n",
    "    color_scale = px.colors.diverging.RdYlGn_r  # Red to Yellow to Green color scale\n",
    "\n",
    "    # Add edges for indices present in multiple classes\n",
    "    for idx in all_indices:\n",
    "        classes_with_idx = [i for i, indices in enumerate(indices_per_class) if idx in indices]\n",
    "        if len(classes_with_idx) > 1:\n",
    "            x = [idx] * len(classes_with_idx)\n",
    "            y = classes_with_idx\n",
    "            color_index = (len(classes_with_idx) - 1) / (num_classes - 1)  # Normalize to [0, 1]\n",
    "            edge_color = px.colors.sample_colorscale(color_scale, [color_index])[0]\n",
    "            \n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=x,\n",
    "                y=y,\n",
    "                mode='lines',\n",
    "                line=dict(color=edge_color, width=2),\n",
    "                hoverinfo='text',\n",
    "                hovertext=f'Index: {idx}<br>Present in {len(classes_with_idx)} classes',\n",
    "                showlegend=False\n",
    "            ))\n",
    "    \n",
    "    # Add scatter plots for each class\n",
    "    for class_idx, indices in enumerate(indices_per_class):\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=indices,\n",
    "            y=[class_idx] * len(indices),\n",
    "            mode='markers',\n",
    "            name=f'Class {class_idx + 1}',\n",
    "            marker=dict(size=4, symbol='circle', color='black'),\n",
    "            hoverinfo='text',\n",
    "            hovertext=[f'Index: {idx}<br>Class: {class_idx + 1}' for idx in indices]\n",
    "        ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        xaxis_title='Activation Index',\n",
    "        yaxis_title='Class',\n",
    "        yaxis=dict(\n",
    "            tickmode='array',\n",
    "            tickvals=list(range(num_classes)),\n",
    "            ticktext=[f'Class {i+1}' for i in range(num_classes)]\n",
    "        ),\n",
    "        hovermode='closest',\n",
    "        width=1500,\n",
    "        height=800,\n",
    "        plot_bgcolor='white',\n",
    "        showlegend=False\n",
    "    )\n",
    "    \n",
    "    fig.update_xaxes(showgrid=True, gridwidth=1, gridcolor='LightGrey')\n",
    "    fig.update_yaxes(showgrid=True, gridwidth=1, gridcolor='LightGrey')\n",
    "    \n",
    "    # Add color bar\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=[None],\n",
    "        y=[None],\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            colorscale=color_scale,\n",
    "            showscale=True,\n",
    "            cmin=1,\n",
    "            cmax=num_classes,\n",
    "            colorbar=dict(\n",
    "                title='Number of Classes',\n",
    "                tickvals=list(range(1, num_classes+1)),\n",
    "                ticktext=list(range(1, num_classes+1))\n",
    "            )\n",
    "        ),\n",
    "        hoverinfo='none',\n",
    "        showlegend=False\n",
    "    ))\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Collect indices for each class\n",
    "max_indices_per_class = []\n",
    "std_indices_per_class = []\n",
    "\n",
    "for fc1 in all_fc_vals:\n",
    "    mask_max, mask_std = compute_masks(fc1, 0.15)\n",
    "    max_indices_per_class.append(np.where(mask_max == 0)[0])\n",
    "    std_indices_per_class.append(np.where(mask_std == 0)[0])\n",
    "\n",
    "# Create and display visualizations\n",
    "output_widgets = []\n",
    "\n",
    "out = Output()\n",
    "with out:\n",
    "    fig_max = create_index_tracking_plot(max_indices_per_class, 'Max Mask Indices Across Classes')\n",
    "    display(fig_max)\n",
    "output_widgets.append(out)\n",
    "\n",
    "out = Output()\n",
    "with out:\n",
    "    fig_std = create_index_tracking_plot(std_indices_per_class, 'Std Mask Indices Across Classes')\n",
    "    display(fig_std)\n",
    "output_widgets.append(out)\n",
    "\n",
    "# Display all visualizations\n",
    "# display(VBox(output_widgets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizer\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from prettytable import PrettyTable\n",
    "from model_distill_bert import getmodel\n",
    "from utilities import compute_accuracy, compute_masks, mask\n",
    "\n",
    "\n",
    "compliment = True\n",
    "results_table = PrettyTable()\n",
    "if(compliment):\n",
    "   results_table.field_names = [\"Class\", \"Base Accuracy\", \"Base Confidence\", \"Base Complement Acc\", \"Base Compliment Conf\", \"STD Accuracy\", \"STD Confidence\", \"STD compliment ACC\", \"STD compliment Conf\", \"Total Masked\"]#, \"Same as Max\"]#\"MAX Accuracy\", \"MAX Confidence\", \"Max compliment acc\", \"Max compliment conf\"\n",
    "# results_table.field_names = [\"Class\", \"Base Accuracy\", \"Base Confidence\", \"STD Accuracy\", \"STD Confidence\", \"Same as Max\"]#, \"MAX Accuracy\", \"MAX Confidence\", \"Max compliment acc\", \"Max compliment conf\"]\n",
    "\n",
    "class_labels = []\n",
    "base_accuracies = []\n",
    "base_confidences = []\n",
    "base_comp_acc = []\n",
    "base_comp_conf = []\n",
    "std_masked_counts = []\n",
    "std_accuracies = []\n",
    "std_confidences = []\n",
    "std_comp_acc = []\n",
    "std_comp_conf = []\n",
    "max_masked_counts = []\n",
    "max_accuracies = []\n",
    "max_confidences = []\n",
    "max_comp_acc = []\n",
    "max_comp_conf = []\n",
    "diff_from_max = []\n",
    "total_masked = []\n",
    "\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"textattack/distilbert-base-uncased-ag-news\")\n",
    "# Check if a GPU is available and use it\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# dataset_test = load_dataset(\"glue\", \"sst2\")\n",
    "\n",
    "# Load the dataset\n",
    "dataset_all = load_dataset(\"fancyzhx/ag_news\")\n",
    "# Select the train split\n",
    "dataset_all = dataset_all['train']\n",
    "\n",
    "# Filter Classes\n",
    "# class_label:\n",
    "    # names:\n",
    "    #     '0': sadness\n",
    "    #     '1': joy\n",
    "    #     '2': love\n",
    "    #     '3': anger\n",
    "    #     '4': fear\n",
    "    #     '5': surprise\n",
    "    \n",
    "\n",
    "for j in range(0,4):\n",
    "    model = getmodel(\"textattack/distilbert-base-uncased-ag-news\")\n",
    "    dataset = dataset_all.filter(lambda x: x['label'] in [j])\n",
    "    dataset_complement = dataset_all.filter(lambda x: x['label'] not in [j])\n",
    "    \n",
    "    if(j==6):\n",
    "        dataset = dataset_all\n",
    "\n",
    "    class_labels.append(f\"Class {j}\")\n",
    "    acc = compute_accuracy(dataset, model, tokenizer)\n",
    "    print(\"Class \",j, \"base accuracy: \", acc)\n",
    "    base_accuracies.append(acc[0])\n",
    "    base_confidences.append(acc[1])\n",
    "    if(compliment):\n",
    "        acc = compute_accuracy(dataset_complement, model, tokenizer)\n",
    "        print(\"Class \",j, \"complement base accuracy: \", acc)\n",
    "        base_comp_acc.append(acc[0])\n",
    "        base_comp_conf.append(acc[1])\n",
    "        \n",
    "\n",
    "    #record the activations of the first fully connected layer, CLS tokken\n",
    "    print(\"Recording activations...\")\n",
    "    progress_bar = tqdm(total=len(dataset))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    fc_vals = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(dataset)):\n",
    "            text = dataset[i]['text']\n",
    "            inputs = tokenizer(text, return_tensors=\"pt\", max_length = 512).to(device)\n",
    "            outputs = model(**inputs)\n",
    "            fc_vals.append(outputs[1].squeeze().cpu().numpy())\n",
    "            progress_bar.update(1)\n",
    "        progress_bar.close()\n",
    "\n",
    "\n",
    "        \n",
    "    mask_max, mask_std,mask_intersection, mask_max_low_std = compute_masks(fc_vals,0.30)\n",
    "    mask_std = mask_max_low_std\n",
    "    # print(\"Masking STD...\")\n",
    "    # model = mask(model,mask_std)\n",
    "    # t = int(mask_std.shape[0]-torch.count_nonzero(mask_std))\n",
    "    # print(\"Total Masked :\", t)\n",
    "    # total_masked.append(t)\n",
    "    # diff_from_max.append(115-(mask_std.shape[0]-torch.count_nonzero(mask_std)))\n",
    "    # acc = compute_accuracy(dataset, model, tokenizer)\n",
    "    # print(\"accuracy after masking STD: \", acc)\n",
    "    # std_accuracies.append(acc[0])\n",
    "    # std_confidences.append(acc[1])\n",
    "    # if(compliment):\n",
    "    #     acc = compute_accuracy(dataset_complement, model, tokenizer)\n",
    "    #     print(\"accuracy after masking STD on complement: \", acc)\n",
    "    #     std_comp_acc.append(acc[0])\n",
    "    #     std_comp_conf.append(acc[1])\n",
    "\n",
    "    print(\"Masking MAX...\")\n",
    "    model = mask(model,mask_max)\n",
    "    t = int(mask_max.shape[0]-torch.count_nonzero(mask_max))\n",
    "    print(\"Total Masked :\", t)\n",
    "    total_masked.append(t)\n",
    "    acc = compute_accuracy(dataset, model, tokenizer)\n",
    "    print(\"accuracy after masking MAX: \", acc)\n",
    "    max_accuracies.append(acc[0])\n",
    "    max_confidences.append(acc[1])\n",
    "    acc = compute_accuracy(dataset_complement, model, tokenizer)\n",
    "    print(\"accuracy after masking MAX on complement: \", acc)\n",
    "    max_comp_acc.append(acc[0])\n",
    "    max_comp_conf.append(acc[1])\n",
    "    if(compliment):\n",
    "        results_table.add_row([\n",
    "            class_labels[j],\n",
    "            base_accuracies[j],\n",
    "            base_confidences[j],\n",
    "            base_comp_acc[j],\n",
    "            base_comp_conf[j],\n",
    "            # std_accuracies[j],\n",
    "            # std_confidences[j],\n",
    "            # std_comp_acc[j],\n",
    "            # std_comp_conf[j],\n",
    "            max_accuracies[j],\n",
    "            max_confidences[j],\n",
    "            max_comp_acc[j],\n",
    "            max_comp_conf[j],\n",
    "            total_masked[j],\n",
    "            # diff_from_max[j]\n",
    "        ])\n",
    "    # results_table.add_row([\n",
    "    #     class_labels[j],\n",
    "    #     base_accuracies[j],\n",
    "    #     base_confidences[j],\n",
    "    #     std_accuracies[j],\n",
    "    #     std_confidences[j],\n",
    "    #     # max_accuracies[j],\n",
    "    #     # max_confidences[j],\n",
    "    #     diff_from_max[j]\n",
    "    # ])\n",
    "\n",
    "print(results_table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "memit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
